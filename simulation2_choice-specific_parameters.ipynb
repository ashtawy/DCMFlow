{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import DCMFlow_093 as dcm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from collections import OrderedDict\n",
    "import time\n",
    "import random\n",
    "import operator\n",
    "import random as rn\n",
    "import os\n",
    "from datetime import datetime\n",
    "import math\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import collections\n",
    "from scipy.stats import truncnorm\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to generate nested logit tree and utility expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_nltree(strct=None):\n",
    "    n_levels = len(strct)\n",
    "    nltree_dict = {'l0':'Root', 'l1':['L1C' + str(n) for n in range(1, strct[0]+1)]}\n",
    "    for level in range(1, n_levels):\n",
    "        level_nests = []\n",
    "        branch_cntr = 1\n",
    "        for p_node in nltree_dict['l'+str(level)]:\n",
    "            for j in range(1, strct[level]+1):\n",
    "                j_node = p_node + '_' + 'L%dC%d'%(level+1, branch_cntr)\n",
    "                level_nests.append(j_node)\n",
    "                branch_cntr += 1\n",
    "        nltree_dict['l'+str(level+1)] = level_nests\n",
    "    return nltree_dict\n",
    "\n",
    "def generate_random_utilities(nltree_dict, n_covariates):\n",
    "    n_levels = len(nltree_dict) - 1\n",
    "    choices = nltree_dict['l'+str(n_levels)]\n",
    "    n_choices = len(choices)\n",
    "    uts = collections.OrderedDict()\n",
    "    for choice in range(n_choices):\n",
    "        uts[choices[choice]] = 'A%d+B%d*X1'%(choice+1, choice+1)\n",
    "    return uts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A function to generate random covariate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_data(nltree_dict, n_cases, \n",
    "                  n_covariates, \n",
    "                  avail_rate_mean=0.1, \n",
    "                  avail_rate_sd=0.05,\n",
    "                  covs_means_mn=0.5,\n",
    "                  covs_means_mx=1.5,\n",
    "                  covs_std_from_means=0.1,\n",
    "                  use_choice_ids=True):\n",
    "    \n",
    "    n_levels = len(nltree_dict) - 1\n",
    "    choices = nltree_dict['l' + str(n_levels)]\n",
    "    n_choices = len(choices)\n",
    "    print('n_choices = %d'%(n_choices))\n",
    "    def gen_choices(n_avail_choices):\n",
    "        n_avail_choices = min(n_choices, n_avail_choices)\n",
    "        if use_choice_ids:\n",
    "            avail_choices = list(np.sort(np.random.choice(choices, n_avail_choices, replace=False)))\n",
    "        else:\n",
    "            avail_choices = list(np.sort(np.random.choice(n_choices, n_avail_choices, replace=False)))\n",
    "        return avail_choices\n",
    "    \n",
    "    loc = avail_rate_mean*n_choices\n",
    "    scale = avail_rate_sd*n_choices\n",
    "    n_avail_choices = truncnorm(a=2, b=n_choices, loc=loc, scale=scale).rvs(size=n_cases).astype(int)\n",
    "    choice_ids_list = list(map(gen_choices, n_avail_choices))\n",
    "    case_ids = []\n",
    "    choice_ids = []\n",
    "    for caseid in range(len(choice_ids_list)):\n",
    "        sub_l = choice_ids_list[caseid]\n",
    "        case_ids.extend([caseid]*len(sub_l))\n",
    "        choice_ids.extend(sub_l)\n",
    "    ncases_times_n_avail_choices = len(choice_ids)\n",
    "    covs_means = np.random.uniform(covs_means_mn, covs_means_mx, n_covariates)\n",
    "    covs = np.random.normal(loc=covs_means, scale=covs_std_from_means*covs_means, \n",
    "                            size=[ncases_times_n_avail_choices, n_covariates])\n",
    "    cov_names = ['X%d'%(i+1) for i in range(n_covariates)]\n",
    "    d_pd = pd.DataFrame(data=covs, columns = cov_names)\n",
    "    d_pd['caseid'] = case_ids\n",
    "    d_pd['choiceid'] = choice_ids\n",
    "    return d_pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Functions to generate random parameter values and constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_random_parameters(nltree_dict, n_covariates=None, theta_bins=None, \n",
    "                          theta_mn=0.65, theta_mx=0.95):\n",
    "    n_levels = len(nltree_dict) - 1\n",
    "    bins = theta_bins\n",
    "    if bins is None:\n",
    "        bnds = np.linspace(start=theta_mn, stop=theta_mx, num=n_levels)\n",
    "        bins = [[bnds[i], None] \n",
    "                if i < n_levels-2 else \n",
    "                [bnds[i], bnds[i+1]] \n",
    "                for i in range(n_levels-1)][::-1]\n",
    "    params_dict = {}\n",
    "    logsum_level = []\n",
    "    for node_name in nltree_dict['l1']:\n",
    "        logsum = np.random.uniform(bins[0][0], bins[0][1])\n",
    "        params_dict[node_name] = logsum\n",
    "        logsum_level.append(logsum)\n",
    "    logsum_levels = [copy.deepcopy(logsum_level)]\n",
    "    for level in range(1, n_levels-1):\n",
    "        logsum_level = []\n",
    "        for i, p_node in enumerate(nltree_dict['l'+str(level)]):\n",
    "            for j, c_node in enumerate(nltree_dict['l'+str(level+1)]):\n",
    "                if p_node in c_node:\n",
    "                    logsum = np.random.uniform(bins[level][0], logsum_levels[level-1][i])\n",
    "                    params_dict[c_node] = logsum\n",
    "                    logsum_level.append(logsum)\n",
    "            logsum_levels.append(logsum_level)\n",
    "    n_choices = len(nltree_dict['l' + str(n_levels)])\n",
    "    n_covariates = n_choices if n_covariates is None else n_covariates\n",
    "    for i in range(n_covariates):\n",
    "        params_dict['A%d'%(i+1)] = np.round(np.random.uniform(1.0, 2.0), 2) \n",
    "        params_dict['B%d'%(i+1)] = np.round(np.random.uniform(-2.0, -0.1), 2) \n",
    "    return params_dict\n",
    "\n",
    "def get_logsum_constraints(nltree_dict):\n",
    "    n_levels = len(nltree_dict) - 1\n",
    "    constraints = {}\n",
    "    for level in range(1, n_levels):\n",
    "        nests = nltree_dict['l%d'%(level)]\n",
    "        for nest in nests:\n",
    "            constraints[nest] = (0, 1.0)\n",
    "    return constraints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Use the functions above to generate the choice tree, utilities, data, and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nltree_dict = generate_nltree(strct=[2,3,4])\n",
    "n_covariates = 1\n",
    "n_levels = len(nltree_dict) - 1\n",
    "choices = nltree_dict['l'+str(n_levels)]\n",
    "n_choices = len(choices)\n",
    "utilities_dict = generate_random_utilities(nltree_dict, n_covariates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('L1C1_L2C1_L3C1', 'A1+B1*X1'),\n",
       "             ('L1C1_L2C1_L3C2', 'A2+B2*X1'),\n",
       "             ('L1C1_L2C1_L3C3', 'A3+B3*X1'),\n",
       "             ('L1C1_L2C1_L3C4', 'A4+B4*X1'),\n",
       "             ('L1C1_L2C2_L3C5', 'A5+B5*X1'),\n",
       "             ('L1C1_L2C2_L3C6', 'A6+B6*X1'),\n",
       "             ('L1C1_L2C2_L3C7', 'A7+B7*X1'),\n",
       "             ('L1C1_L2C2_L3C8', 'A8+B8*X1'),\n",
       "             ('L1C1_L2C3_L3C9', 'A9+B9*X1'),\n",
       "             ('L1C1_L2C3_L3C10', 'A10+B10*X1'),\n",
       "             ('L1C1_L2C3_L3C11', 'A11+B11*X1'),\n",
       "             ('L1C1_L2C3_L3C12', 'A12+B12*X1'),\n",
       "             ('L1C2_L2C4_L3C13', 'A13+B13*X1'),\n",
       "             ('L1C2_L2C4_L3C14', 'A14+B14*X1'),\n",
       "             ('L1C2_L2C4_L3C15', 'A15+B15*X1'),\n",
       "             ('L1C2_L2C4_L3C16', 'A16+B16*X1'),\n",
       "             ('L1C2_L2C5_L3C17', 'A17+B17*X1'),\n",
       "             ('L1C2_L2C5_L3C18', 'A18+B18*X1'),\n",
       "             ('L1C2_L2C5_L3C19', 'A19+B19*X1'),\n",
       "             ('L1C2_L2C5_L3C20', 'A20+B20*X1'),\n",
       "             ('L1C2_L2C6_L3C21', 'A21+B21*X1'),\n",
       "             ('L1C2_L2C6_L3C22', 'A22+B22*X1'),\n",
       "             ('L1C2_L2C6_L3C23', 'A23+B23*X1'),\n",
       "             ('L1C2_L2C6_L3C24', 'A24+B24*X1')])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utilities_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_choices = 24\n"
     ]
    }
   ],
   "source": [
    "n_cases = 80000\n",
    "data = generate_data(nltree_dict, n_cases=n_cases, n_covariates=n_covariates, \n",
    "                     avail_rate_mean=0.5, avail_rate_sd=0.1,\n",
    "                     covs_std_from_means=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>caseid</th>\n",
       "      <th>choiceid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.354777</td>\n",
       "      <td>0</td>\n",
       "      <td>L1C1_L2C1_L3C2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.215865</td>\n",
       "      <td>0</td>\n",
       "      <td>L1C1_L2C1_L3C4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.099582</td>\n",
       "      <td>0</td>\n",
       "      <td>L1C1_L2C2_L3C6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.334179</td>\n",
       "      <td>0</td>\n",
       "      <td>L1C1_L2C2_L3C7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.151389</td>\n",
       "      <td>0</td>\n",
       "      <td>L1C1_L2C2_L3C8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         X1  caseid        choiceid\n",
       "0  1.354777       0  L1C1_L2C1_L3C2\n",
       "1  1.215865       0  L1C1_L2C1_L3C4\n",
       "2  1.099582       0  L1C1_L2C2_L3C6\n",
       "3  1.334179       0  L1C1_L2C2_L3C7\n",
       "4  1.151389       0  L1C1_L2C2_L3C8"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "true_params_dict = generate_random_parameters(nltree_dict, n_covariates=n_choices, \n",
    "                                         theta_mn=0.6, theta_mx=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate an NLFlow model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import DCMFlow_094 as dcm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = dcm.NLFlow(nltree_dict=nltree_dict, utilities_dict=utilities_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulate choices & compute loglikelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loglikelihood (sum/mean) = 195441.6/2.443\n"
     ]
    }
   ],
   "source": [
    "choices_and_ll = m.compute_choices_and_likelihood(data, true_params_dict)\n",
    "if choices_and_ll is not None:\n",
    "    simulated_choices, ll = choices_and_ll\n",
    "    data_with_y = data.copy()\n",
    "    data_with_y['chosen'] = simulated_choices['chosen'].copy()\n",
    "    print('Loglikelihood (sum/mean) = %.1f/%.3f'%(-ll, -ll/n_cases))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimate the model's parameters using the L-BFGS-B optimizer (and compare them with true values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Digesting the data...\n",
      "\n",
      "Starting the optimization process using l-bfgs-b\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
      "  Objective function value: 195416.468750\n",
      "  Number of iterations: 84\n",
      "  Number of functions evaluations: 106\n",
      "Loglikelihood (Sum/Mean)=195416.5/2.443, T=3s, Cf/Ls/Cn MAPE=7.8/4.7/104.1%, RMSE=0.110/0.039/1.579\n"
     ]
    }
   ],
   "source": [
    "constraints_dict = get_logsum_constraints(nltree_dict)\n",
    "m.fit(data_with_y, optimizer='l-bfgs-b',\n",
    "      true_params_dict=true_params_dict, \n",
    "      constraints_dict=constraints_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print estimated and true parameters side by side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_type</th>\n",
       "      <th>param_name</th>\n",
       "      <th>param_est_val</th>\n",
       "      <th>param_true_val</th>\n",
       "      <th>relative_perc_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logsum</td>\n",
       "      <td>L1C1</td>\n",
       "      <td>0.752554</td>\n",
       "      <td>0.762773</td>\n",
       "      <td>1.339652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logsum</td>\n",
       "      <td>L1C2</td>\n",
       "      <td>0.810736</td>\n",
       "      <td>0.765592</td>\n",
       "      <td>5.896681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logsum</td>\n",
       "      <td>L1C1_L2C1</td>\n",
       "      <td>0.657672</td>\n",
       "      <td>0.671894</td>\n",
       "      <td>2.116656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logsum</td>\n",
       "      <td>L1C1_L2C2</td>\n",
       "      <td>0.599273</td>\n",
       "      <td>0.617881</td>\n",
       "      <td>3.011443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Logsum</td>\n",
       "      <td>L1C1_L2C3</td>\n",
       "      <td>0.684439</td>\n",
       "      <td>0.665747</td>\n",
       "      <td>2.807725</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_type param_name  param_est_val  param_true_val  relative_perc_error\n",
       "0     Logsum       L1C1       0.752554        0.762773             1.339652\n",
       "1     Logsum       L1C2       0.810736        0.765592             5.896681\n",
       "2     Logsum  L1C1_L2C1       0.657672        0.671894             2.116656\n",
       "3     Logsum  L1C1_L2C2       0.599273        0.617881             3.011443\n",
       "4     Logsum  L1C1_L2C3       0.684439        0.665747             2.807725"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.get_estimated_parameters(true_params_dict=true_params_dict).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You could also employ Adam to optimize using stochastic-gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You could use `m.fit(data_with_y, optimizer='adam', ...)`, however, that would run Adam in batch mode where at each \n",
    "iteration the entire data will be used to update the parameters. To run Adam on smaller samples of the data (mini-batches), you will need create and AdamOptimizer object and set its step_size to the desired value, E.g., below I use 5000 cases, I can also set other hyper-parameters as shown below and the left (not listed) assigned to their default values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt = dcm.AdamOptimizer(n_steps=100, log_every_n_epochs=10, \n",
    "                        step_size=10000, learning_rate=2e-4, \n",
    "                        patience=2000, epsilon=1e-8,\n",
    "                        interior_point_penalty_term=0.0005,\n",
    "                        objective='loglikelihood_sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Digesting the data...\n",
      "\n",
      "Starting the optimization process using adam\n",
      "\n",
      "\n",
      "Abbreviations key:\n",
      "S: Step, E: Epoch, L: Loglikelihood, S/M: Sum/Mean\n",
      "C: Cost (loglikehood + penalty terms for constrained \n",
      "   parameters, printed when constraints are used)\n",
      "T: Time, Cf/Ls/Cn: Coefficient/Logsum/Constant\n",
      "MAPE: Mean Absolute Percentage Error (printed when true\n",
      "      parameters are provided)\n",
      "RMSE: Root Mean Square Error (printed when true parameters\n",
      "      are provided)\n",
      "\n",
      "\n",
      "S/E=8/1, L(S/M)=227298.4/2.841, C(S/M)=227298.5/2.841, T=0s, Cf/Ls/Cn MAPE=100.1/29.5/100.0%, RMSE=1.167/0.208/1.608\n",
      "S/E=80/10, L(S/M)=224914.0/2.811, C(S/M)=224914.1/2.811, T=6s, Cf/Ls/Cn MAPE=100.9/29.4/100.3%, RMSE=1.158/0.209/1.610\n",
      "S/E=100/12, L(S/M)=112111.3/2.803, C(S/M)=112111.4/2.803, T=7s, Cf/Ls/Cn MAPE=101.1/29.4/100.4%, RMSE=1.155/0.209/1.611\n",
      "****************************************************************************************************\n",
      "STILL CONVERGING: Improvement in Cost of 112310 fell under the Improvement Threshold (1e-30) 0/2000 times\n",
      " Max number of steps (100) has been reached.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "m.fit(data_with_y, optimizer=opt, \n",
    "      true_params_dict=true_params_dict,\n",
    "      constraints_dict=constraints_dict,\n",
    "      start_over=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
